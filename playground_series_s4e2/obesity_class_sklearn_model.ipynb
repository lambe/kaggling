{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv-3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "import optuna\n",
    "\n",
    "# ROOT = '/kaggle/input/playground-series-s4e2'\n",
    "ROOT = 'competition_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(ROOT, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = df_train.drop(columns=[\"NObeyesdad\"])\n",
    "y = df_train[\"NObeyesdad\"]\n",
    "\n",
    "def feature_eng(df_X_raw):\n",
    "    # Set aside ID column for now\n",
    "    X_id = df_X_raw[[\"id\"]]\n",
    "\n",
    "    # Convert categorical data to numerical features\n",
    "    cat_cols = [\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"CAEC\", \"SMOKE\", \"SCC\", \"CALC\", \"MTRANS\"]\n",
    "    feature_cats = [[\"Female\", \"Male\"],\n",
    "                    [\"yes\", \"no\"],\n",
    "                    [\"yes\", \"no\"],\n",
    "                    [\"no\", \"Sometimes\", \"Frequently\", \"Always\"],\n",
    "                    [\"yes\", \"no\"],\n",
    "                    [\"yes\", \"no\"],\n",
    "                    [\"no\", \"Sometimes\", \"Frequently\", \"Always\"],\n",
    "                    [\"Automobile\", \"Motorbike\", \"Public_Transportation\", \"Bike\", \"Walking\"]]\n",
    "    enc = preprocessing.OrdinalEncoder(categories=feature_cats)\n",
    "    X_encoded = enc.fit_transform(df_X_raw[cat_cols])\n",
    "    X_cat = pd.DataFrame(X_encoded, df_X_raw.index, cat_cols)\n",
    "\n",
    "    # Normalize numerical features\n",
    "    norm_cols = [\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]\n",
    "    # scaler = preprocessing.StandardScaler()\n",
    "    # X_norm = scaler.fit_transform(df_X_raw[norm_cols])\n",
    "    # X_norm = pd.DataFrame(X_norm, df_X_raw.index, norm_cols)\n",
    "    X_norm = df_X_raw[norm_cols]\n",
    "\n",
    "    X = pd.concat([X_id, X_norm, X_cat], axis=1)\n",
    "\n",
    "    # New features with some predictive power\n",
    "    X[\"BMI\"] = X[\"Weight\"] / X[\"Height\"]**2\n",
    "    X[\"Veg_and_water\"] = X[\"FCVC\"] * X[\"CH2O\"]\n",
    "    X[\"Discounted_activity\"] = X[\"FAF\"] / (X[\"TUE\"] + 1)\n",
    "    X[\"High_cal_snacking\"] = X[\"FAVC\"] * X[\"CAEC\"]\n",
    "    return X\n",
    "\n",
    "X = feature_eng(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick model tests:\n",
    "- Logistic regression = 67-73% accuracy (with data normalization)\n",
    "- Linear SVM = too slow\n",
    "- Basic Decision Tree = 77-85% accuracy\n",
    "- Random Forest = 89.4-90.4% accuracy\n",
    "- Histogram-based Gradient Boosting = 82.2-90.8% accuracy (and takes only 10s to evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87837187 0.89450867 0.9077553  0.89809684 0.83594315]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate logistic regression on this dataset\n",
    "# model = linear_model.LogisticRegression(max_iter=1000)\n",
    "# model = svm.SVC(kernel='linear')\n",
    "# model = tree.DecisionTreeClassifier()\n",
    "# model = ensemble.RandomForestClassifier()\n",
    "model = ensemble.HistGradientBoostingClassifier()\n",
    "\n",
    "scores = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(scores)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "# print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization with optuna\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 300)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 10, 100)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = ensemble.HistGradientBoostingClassifier(max_depth=max_depth, \n",
    "                                                    max_iter=n_estimators,\n",
    "                                                    learning_rate=learning_rate, \n",
    "                                                    max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    accuracy = scores.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-08 15:20:27,929] A new study created in memory with name: no-name-b57071cc-48f4-4ae0-b358-448b5b026ff3\n",
      "[I 2024-02-08 15:21:32,955] Trial 0 finished with value: 0.8733502477987756 and parameters: {'max_depth': 7, 'n_estimators': 271, 'max_leaf_nodes': 70, 'learning_rate': 0.0004917019689861579}. Best is trial 0 with value: 0.8733502477987756.\n",
      "[I 2024-02-08 15:22:18,789] Trial 1 finished with value: 0.8952210600876638 and parameters: {'max_depth': 6, 'n_estimators': 235, 'max_leaf_nodes': 71, 'learning_rate': 0.008625953261228283}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:22:42,416] Trial 2 finished with value: 0.8925235416959676 and parameters: {'max_depth': 7, 'n_estimators': 85, 'max_leaf_nodes': 95, 'learning_rate': 0.013150191392593767}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:22:57,360] Trial 3 finished with value: 0.8852960425999447 and parameters: {'max_depth': 10, 'n_estimators': 132, 'max_leaf_nodes': 65, 'learning_rate': 0.08158864831573909}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:23:10,857] Trial 4 finished with value: 0.892282473429575 and parameters: {'max_depth': 5, 'n_estimators': 146, 'max_leaf_nodes': 14, 'learning_rate': 0.01661927744192434}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:24:06,430] Trial 5 finished with value: 0.8901617828700654 and parameters: {'max_depth': 9, 'n_estimators': 167, 'max_leaf_nodes': 92, 'learning_rate': 0.018779995342403617}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:24:51,236] Trial 6 finished with value: 0.885875516218438 and parameters: {'max_depth': 8, 'n_estimators': 197, 'max_leaf_nodes': 52, 'learning_rate': 0.001360437783849727}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:25:03,819] Trial 7 finished with value: 0.884622968488685 and parameters: {'max_depth': 3, 'n_estimators': 177, 'max_leaf_nodes': 80, 'learning_rate': 0.013936372983901808}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:25:33,140] Trial 8 finished with value: 0.8796129284259102 and parameters: {'max_depth': 6, 'n_estimators': 288, 'max_leaf_nodes': 16, 'learning_rate': 0.001494953614379693}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:25:43,982] Trial 9 finished with value: 0.8452167896957299 and parameters: {'max_depth': 3, 'n_estimators': 160, 'max_leaf_nodes': 85, 'learning_rate': 0.0009158464359959965}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:25:48,150] Trial 10 finished with value: 0.19491280277426942 and parameters: {'max_depth': 5, 'n_estimators': 31, 'max_leaf_nodes': 39, 'learning_rate': 0.00011064826901375607}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:26:03,755] Trial 11 finished with value: 0.8872245075008042 and parameters: {'max_depth': 7, 'n_estimators': 66, 'max_leaf_nodes': 95, 'learning_rate': 0.006563340500900154}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:26:17,550] Trial 12 finished with value: 0.8795625888601257 and parameters: {'max_depth': 5, 'n_estimators': 233, 'max_leaf_nodes': 74, 'learning_rate': 0.07914617436264863}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:26:39,763] Trial 13 finished with value: 0.8893922303932149 and parameters: {'max_depth': 7, 'n_estimators': 108, 'max_leaf_nodes': 53, 'learning_rate': 0.0048872831981705365}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:26:44,760] Trial 14 finished with value: 0.880190997920969 and parameters: {'max_depth': 2, 'n_estimators': 91, 'max_leaf_nodes': 100, 'learning_rate': 0.03873550207309345}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:26:47,034] Trial 15 finished with value: 0.7989218884972816 and parameters: {'max_depth': 9, 'n_estimators': 11, 'max_leaf_nodes': 39, 'learning_rate': 0.006792405519619606}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:27:25,964] Trial 16 finished with value: 0.8864054277609824 and parameters: {'max_depth': 6, 'n_estimators': 227, 'max_leaf_nodes': 64, 'learning_rate': 0.003035723288070889}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:27:32,252] Trial 17 finished with value: 0.8851528684269037 and parameters: {'max_depth': 4, 'n_estimators': 63, 'max_leaf_nodes': 84, 'learning_rate': 0.03139847827382319}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:28:07,730] Trial 18 finished with value: 0.8906447084970124 and parameters: {'max_depth': 8, 'n_estimators': 200, 'max_leaf_nodes': 38, 'learning_rate': 0.002982596718943911}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:28:51,608] Trial 19 finished with value: 0.8950281033564815 and parameters: {'max_depth': 6, 'n_estimators': 249, 'max_leaf_nodes': 90, 'learning_rate': 0.010571175313496207}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:29:36,116] Trial 20 finished with value: 0.8279708234754585 and parameters: {'max_depth': 6, 'n_estimators': 258, 'max_leaf_nodes': 76, 'learning_rate': 0.0003512756227660575}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:30:49,482] Trial 21 finished with value: 0.8949316481995424 and parameters: {'max_depth': 8, 'n_estimators': 245, 'max_leaf_nodes': 89, 'learning_rate': 0.00924596386905144}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:31:57,620] Trial 22 finished with value: 0.8943536483304392 and parameters: {'max_depth': 8, 'n_estimators': 244, 'max_leaf_nodes': 86, 'learning_rate': 0.00859999087463986}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:32:26,470] Trial 23 finished with value: 0.8845728378007667 and parameters: {'max_depth': 5, 'n_estimators': 285, 'max_leaf_nodes': 60, 'learning_rate': 0.027310754974568984}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:33:32,192] Trial 24 finished with value: 0.8943540776904978 and parameters: {'max_depth': 10, 'n_estimators': 211, 'max_leaf_nodes': 88, 'learning_rate': 0.0038293005599121083}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:34:25,143] Trial 25 finished with value: 0.892763507551399 and parameters: {'max_depth': 6, 'n_estimators': 299, 'max_leaf_nodes': 78, 'learning_rate': 0.00970872311312868}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:34:47,860] Trial 26 finished with value: 0.8870782233684202 and parameters: {'max_depth': 4, 'n_estimators': 257, 'max_leaf_nodes': 70, 'learning_rate': 0.0375436450724241}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:36:06,063] Trial 27 finished with value: 0.895076737086358 and parameters: {'max_depth': 9, 'n_estimators': 222, 'max_leaf_nodes': 99, 'learning_rate': 0.005060297461831331}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:37:19,792] Trial 28 finished with value: 0.8894884882766136 and parameters: {'max_depth': 9, 'n_estimators': 216, 'max_leaf_nodes': 99, 'learning_rate': 0.0022381241884351895}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:37:44,456] Trial 29 finished with value: 0.8631373966112583 and parameters: {'max_depth': 4, 'n_estimators': 273, 'max_leaf_nodes': 72, 'learning_rate': 0.0005681418650992443}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:38:16,798] Trial 30 finished with value: 0.8895849782465307 and parameters: {'max_depth': 6, 'n_estimators': 187, 'max_leaf_nodes': 82, 'learning_rate': 0.005709484782019833}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:39:32,106] Trial 31 finished with value: 0.894401620613739 and parameters: {'max_depth': 8, 'n_estimators': 247, 'max_leaf_nodes': 90, 'learning_rate': 0.008802972074244996}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:40:24,037] Trial 32 finished with value: 0.8872228828951773 and parameters: {'max_depth': 7, 'n_estimators': 267, 'max_leaf_nodes': 94, 'learning_rate': 0.022476232978043475}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:41:47,697] Trial 33 finished with value: 0.8951724495664392 and parameters: {'max_depth': 10, 'n_estimators': 228, 'max_leaf_nodes': 99, 'learning_rate': 0.012069258985674689}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:43:08,342] Trial 34 finished with value: 0.8933415538378059 and parameters: {'max_depth': 10, 'n_estimators': 224, 'max_leaf_nodes': 99, 'learning_rate': 0.012000782232878806}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:44:16,595] Trial 35 finished with value: 0.8935834924286414 and parameters: {'max_depth': 9, 'n_estimators': 203, 'max_leaf_nodes': 96, 'learning_rate': 0.004407172663273131}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:44:45,226] Trial 36 finished with value: 0.8838988585520864 and parameters: {'max_depth': 10, 'n_estimators': 128, 'max_leaf_nodes': 68, 'learning_rate': 0.047119142083653656}. Best is trial 1 with value: 0.8952210600876638.\n",
      "[I 2024-02-08 15:45:21,349] Trial 37 finished with value: 0.8953652090240809 and parameters: {'max_depth': 7, 'n_estimators': 183, 'max_leaf_nodes': 45, 'learning_rate': 0.0139111241803044}. Best is trial 37 with value: 0.8953652090240809.\n",
      "[I 2024-02-08 15:45:49,008] Trial 38 finished with value: 0.8922814986661987 and parameters: {'max_depth': 9, 'n_estimators': 180, 'max_leaf_nodes': 29, 'learning_rate': 0.017576382813362795}. Best is trial 37 with value: 0.8953652090240809.\n",
      "[I 2024-02-08 15:46:04,597] Trial 39 finished with value: 0.8809113712646255 and parameters: {'max_depth': 10, 'n_estimators': 137, 'max_leaf_nodes': 47, 'learning_rate': 0.062449873797127076}. Best is trial 37 with value: 0.8953652090240809.\n",
      "[I 2024-02-08 15:46:35,501] Trial 40 finished with value: 0.88611638721129 and parameters: {'max_depth': 7, 'n_estimators': 161, 'max_leaf_nodes': 48, 'learning_rate': 0.0022275844845672083}. Best is trial 37 with value: 0.8953652090240809.\n",
      "[I 2024-02-08 15:47:29,986] Trial 41 finished with value: 0.8955097525075789 and parameters: {'max_depth': 7, 'n_estimators': 235, 'max_leaf_nodes': 92, 'learning_rate': 0.012572570295554173}. Best is trial 41 with value: 0.8955097525075789.\n",
      "[I 2024-02-08 15:48:22,552] Trial 42 finished with value: 0.8927632870692068 and parameters: {'max_depth': 7, 'n_estimators': 232, 'max_leaf_nodes': 58, 'learning_rate': 0.015957080418855036}. Best is trial 41 with value: 0.8955097525075789.\n",
      "[I 2024-02-08 15:48:52,960] Trial 43 finished with value: 0.8838982551271393 and parameters: {'max_depth': 9, 'n_estimators': 192, 'max_leaf_nodes': 32, 'learning_rate': 0.023197113373514072}. Best is trial 41 with value: 0.8955097525075789.\n",
      "[I 2024-02-08 15:49:34,440] Trial 44 finished with value: 0.8950280221262001 and parameters: {'max_depth': 7, 'n_estimators': 173, 'max_leaf_nodes': 94, 'learning_rate': 0.014024995027343362}. Best is trial 41 with value: 0.8955097525075789.\n",
      "[I 2024-02-08 15:50:36,668] Trial 45 finished with value: 0.8957030109512344 and parameters: {'max_depth': 8, 'n_estimators': 217, 'max_leaf_nodes': 79, 'learning_rate': 0.0062417168596132664}. Best is trial 45 with value: 0.8957030109512344.\n",
      "[I 2024-02-08 15:51:30,927] Trial 46 finished with value: 0.8956066486289025 and parameters: {'max_depth': 8, 'n_estimators': 212, 'max_leaf_nodes': 64, 'learning_rate': 0.00698118570178591}. Best is trial 45 with value: 0.8957030109512344.\n",
      "[I 2024-02-08 15:52:21,597] Trial 47 finished with value: 0.8874652508460714 and parameters: {'max_depth': 8, 'n_estimators': 205, 'max_leaf_nodes': 64, 'learning_rate': 0.001483296980540002}. Best is trial 45 with value: 0.8957030109512344.\n",
      "[I 2024-02-08 15:52:55,485] Trial 48 finished with value: 0.8925716184182004 and parameters: {'max_depth': 7, 'n_estimators': 153, 'max_leaf_nodes': 60, 'learning_rate': 0.006701088070321668}. Best is trial 45 with value: 0.8957030109512344.\n",
      "[I 2024-02-08 15:53:22,070] Trial 49 finished with value: 0.8882842609599377 and parameters: {'max_depth': 5, 'n_estimators': 210, 'max_leaf_nodes': 80, 'learning_rate': 0.007105780739592106}. Best is trial 45 with value: 0.8957030109512344.\n",
      "[I 2024-02-08 15:54:19,137] Trial 50 finished with value: 0.8894403651370772 and parameters: {'max_depth': 8, 'n_estimators': 275, 'max_leaf_nodes': 46, 'learning_rate': 0.0020623174325824327}. Best is trial 45 with value: 0.8957030109512344.\n",
      "[I 2024-02-08 15:55:01,600] Trial 51 finished with value: 0.8963286697868378 and parameters: {'max_depth': 6, 'n_estimators': 234, 'max_leaf_nodes': 68, 'learning_rate': 0.01220497187409835}. Best is trial 51 with value: 0.8963286697868378.\n",
      "[I 2024-02-08 15:55:55,305] Trial 52 finished with value: 0.8858257800776006 and parameters: {'max_depth': 7, 'n_estimators': 239, 'max_leaf_nodes': 75, 'learning_rate': 0.01976087118902018}. Best is trial 51 with value: 0.8963286697868378.\n",
      "[I 2024-02-08 15:56:28,172] Trial 53 finished with value: 0.896328901873356 and parameters: {'max_depth': 6, 'n_estimators': 179, 'max_leaf_nodes': 67, 'learning_rate': 0.014506124949613114}. Best is trial 53 with value: 0.896328901873356.\n",
      "[I 2024-02-08 15:57:00,448] Trial 54 finished with value: 0.8966662512317992 and parameters: {'max_depth': 6, 'n_estimators': 183, 'max_leaf_nodes': 66, 'learning_rate': 0.014965859019255488}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 15:57:30,111] Trial 55 finished with value: 0.8857793047523428 and parameters: {'max_depth': 6, 'n_estimators': 169, 'max_leaf_nodes': 67, 'learning_rate': 0.003982134183485666}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 15:57:54,603] Trial 56 finished with value: 0.8900168216308348 and parameters: {'max_depth': 5, 'n_estimators': 192, 'max_leaf_nodes': 63, 'learning_rate': 0.028545067417676182}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 15:58:36,816] Trial 57 finished with value: 0.8950766674604026 and parameters: {'max_depth': 6, 'n_estimators': 217, 'max_leaf_nodes': 55, 'learning_rate': 0.007846493454039852}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 15:59:16,494] Trial 58 finished with value: 0.8941610165203825 and parameters: {'max_depth': 6, 'n_estimators': 196, 'max_leaf_nodes': 72, 'learning_rate': 0.010796066452601925}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:00:00,014] Trial 59 finished with value: 0.19491280277426942 and parameters: {'max_depth': 8, 'n_estimators': 150, 'max_leaf_nodes': 67, 'learning_rate': 0.00017389544058563764}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:00:38,735] Trial 60 finished with value: 0.8799500805108131 and parameters: {'max_depth': 5, 'n_estimators': 256, 'max_leaf_nodes': 79, 'learning_rate': 0.003072513789809195}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:01:24,950] Trial 61 finished with value: 0.8953167957763967 and parameters: {'max_depth': 7, 'n_estimators': 186, 'max_leaf_nodes': 52, 'learning_rate': 0.015337755593323062}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:02:36,899] Trial 62 finished with value: 0.8920418809405446 and parameters: {'max_depth': 7, 'n_estimators': 179, 'max_leaf_nodes': 58, 'learning_rate': 0.005797922581890675}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:04:09,276] Trial 63 finished with value: 0.8845733251824548 and parameters: {'max_depth': 8, 'n_estimators': 236, 'max_leaf_nodes': 73, 'learning_rate': 0.018488356693312592}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:04:50,527] Trial 64 finished with value: 0.8944984935264108 and parameters: {'max_depth': 6, 'n_estimators': 161, 'max_leaf_nodes': 61, 'learning_rate': 0.011627835551369077}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:05:25,060] Trial 65 finished with value: 0.894786895838178 and parameters: {'max_depth': 6, 'n_estimators': 140, 'max_leaf_nodes': 69, 'learning_rate': 0.023072222955386003}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:06:03,216] Trial 66 finished with value: 0.8852955088009529 and parameters: {'max_depth': 7, 'n_estimators': 210, 'max_leaf_nodes': 44, 'learning_rate': 0.03494908032900726}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:06:39,477] Trial 67 finished with value: 0.8935347774684839 and parameters: {'max_depth': 5, 'n_estimators': 203, 'max_leaf_nodes': 84, 'learning_rate': 0.014058941733352101}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:07:09,757] Trial 68 finished with value: 0.8871263465079566 and parameters: {'max_depth': 6, 'n_estimators': 125, 'max_leaf_nodes': 54, 'learning_rate': 0.047947587677961735}. Best is trial 54 with value: 0.8966662512317992.\n",
      "[I 2024-02-08 16:08:37,157] Trial 69 finished with value: 0.8969071338289772 and parameters: {'max_depth': 8, 'n_estimators': 220, 'max_leaf_nodes': 76, 'learning_rate': 0.00880988103245412}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:10:03,093] Trial 70 finished with value: 0.8945468719611173 and parameters: {'max_depth': 8, 'n_estimators': 221, 'max_leaf_nodes': 75, 'learning_rate': 0.0053619910231642014}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:11:31,833] Trial 71 finished with value: 0.8953174804316252 and parameters: {'max_depth': 8, 'n_estimators': 184, 'max_leaf_nodes': 77, 'learning_rate': 0.008542172588786258}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:12:45,956] Trial 72 finished with value: 0.8954135294371577 and parameters: {'max_depth': 7, 'n_estimators': 229, 'max_leaf_nodes': 63, 'learning_rate': 0.010182700696869147}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:14:27,786] Trial 73 finished with value: 0.895028184586763 and parameters: {'max_depth': 8, 'n_estimators': 233, 'max_leaf_nodes': 70, 'learning_rate': 0.00990424973843151}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:15:48,006] Trial 74 finished with value: 0.8965218237915604 and parameters: {'max_depth': 7, 'n_estimators': 253, 'max_leaf_nodes': 66, 'learning_rate': 0.007644802304088078}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:16:55,782] Trial 75 finished with value: 0.8885732666966522 and parameters: {'max_depth': 6, 'n_estimators': 266, 'max_leaf_nodes': 82, 'learning_rate': 0.0037421420816334872}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:18:20,989] Trial 76 finished with value: 0.896473689047698 and parameters: {'max_depth': 8, 'n_estimators': 248, 'max_leaf_nodes': 66, 'learning_rate': 0.007256130169741249}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:19:49,520] Trial 77 finished with value: 0.8957509484215563 and parameters: {'max_depth': 8, 'n_estimators': 247, 'max_leaf_nodes': 65, 'learning_rate': 0.00723967823445913}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:21:24,328] Trial 78 finished with value: 0.8944023052689675 and parameters: {'max_depth': 9, 'n_estimators': 283, 'max_leaf_nodes': 66, 'learning_rate': 0.004725367629181692}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:22:47,888] Trial 79 finished with value: 0.895799303647611 and parameters: {'max_depth': 8, 'n_estimators': 253, 'max_leaf_nodes': 58, 'learning_rate': 0.0061153732653161045}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:24:14,965] Trial 80 finished with value: 0.8955579916903744 and parameters: {'max_depth': 9, 'n_estimators': 254, 'max_leaf_nodes': 57, 'learning_rate': 0.00839539382770887}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:25:24,946] Trial 81 finished with value: 0.8947394109365666 and parameters: {'max_depth': 8, 'n_estimators': 244, 'max_leaf_nodes': 61, 'learning_rate': 0.006465151600508692}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:26:42,643] Trial 82 finished with value: 0.8930052836816721 and parameters: {'max_depth': 8, 'n_estimators': 266, 'max_leaf_nodes': 71, 'learning_rate': 0.003595731134432389}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:26:56,670] Trial 83 finished with value: 0.8616921358411673 and parameters: {'max_depth': 2, 'n_estimators': 251, 'max_leaf_nodes': 68, 'learning_rate': 0.005464693798335947}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:28:09,247] Trial 84 finished with value: 0.8950765282084916 and parameters: {'max_depth': 9, 'n_estimators': 241, 'max_leaf_nodes': 73, 'learning_rate': 0.007511866781742401}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:29:19,000] Trial 85 finished with value: 0.8942578430157507 and parameters: {'max_depth': 8, 'n_estimators': 278, 'max_leaf_nodes': 66, 'learning_rate': 0.0046267963813333675}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:30:30,059] Trial 86 finished with value: 0.8957512153210523 and parameters: {'max_depth': 8, 'n_estimators': 260, 'max_leaf_nodes': 76, 'learning_rate': 0.006127526863675929}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:31:28,948] Trial 87 finished with value: 0.8912228708266783 and parameters: {'max_depth': 7, 'n_estimators': 300, 'max_leaf_nodes': 50, 'learning_rate': 0.002810283759518241}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:32:13,811] Trial 88 finished with value: 0.895750751148016 and parameters: {'max_depth': 6, 'n_estimators': 262, 'max_leaf_nodes': 62, 'learning_rate': 0.009666598712132433}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:33:06,879] Trial 89 finished with value: 0.8881860651541125 and parameters: {'max_depth': 8, 'n_estimators': 263, 'max_leaf_nodes': 58, 'learning_rate': 0.019880635152807215}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:34:14,603] Trial 90 finished with value: 0.8880427749378125 and parameters: {'max_depth': 9, 'n_estimators': 247, 'max_leaf_nodes': 77, 'learning_rate': 0.01217971174783637}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:35:02,171] Trial 91 finished with value: 0.8948836411032651 and parameters: {'max_depth': 6, 'n_estimators': 290, 'max_leaf_nodes': 62, 'learning_rate': 0.009140361932648347}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:35:44,754] Trial 92 finished with value: 0.8900170305087011 and parameters: {'max_depth': 6, 'n_estimators': 262, 'max_leaf_nodes': 65, 'learning_rate': 0.015273630109989061}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:36:15,607] Trial 93 finished with value: 0.8943538456039797 and parameters: {'max_depth': 5, 'n_estimators': 259, 'max_leaf_nodes': 71, 'learning_rate': 0.011242943024633056}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:37:00,980] Trial 94 finished with value: 0.8948838151681537 and parameters: {'max_depth': 6, 'n_estimators': 272, 'max_leaf_nodes': 69, 'learning_rate': 0.0075662290931924866}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:37:52,633] Trial 95 finished with value: 0.8949317642428014 and parameters: {'max_depth': 7, 'n_estimators': 250, 'max_leaf_nodes': 57, 'learning_rate': 0.009793558472152053}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:38:17,711] Trial 96 finished with value: 0.8918007082352186 and parameters: {'max_depth': 6, 'n_estimators': 290, 'max_leaf_nodes': 12, 'learning_rate': 0.006103284883288779}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:39:07,622] Trial 97 finished with value: 0.8898257796134275 and parameters: {'max_depth': 7, 'n_estimators': 240, 'max_leaf_nodes': 60, 'learning_rate': 0.0026178539603365293}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:39:57,707] Trial 98 finished with value: 0.8943533234093138 and parameters: {'max_depth': 7, 'n_estimators': 227, 'max_leaf_nodes': 74, 'learning_rate': 0.016663194656997077}. Best is trial 69 with value: 0.8969071338289772.\n",
      "[I 2024-02-08 16:40:28,409] Trial 99 finished with value: 0.8917527823692227 and parameters: {'max_depth': 8, 'n_estimators': 272, 'max_leaf_nodes': 19, 'learning_rate': 0.00414102845549158}. Best is trial 69 with value: 0.8969071338289772.\n"
     ]
    }
   ],
   "source": [
    "# # Comment out this block when scoring on the test data\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89258189 0.89210019 0.9026975  0.90002409 0.89086967]\n"
     ]
    }
   ],
   "source": [
    "# Create the model with the optimal hyperparameters\n",
    "model = ensemble.HistGradientBoostingClassifier(max_depth=8,\n",
    "                                                max_iter=220,\n",
    "                                                learning_rate=0.0088,\n",
    "                                                max_leaf_nodes=76)\n",
    "\n",
    "scores = model_selection.cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.932\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model on training set to reduce model bias\n",
    "# model.fit(X_train, y_train)\n",
    "model.fit(X, y)\n",
    "y_pred_test = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy: {accuracy:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # OPTIONAL: Examine misclassified samples from the training set\n",
    "# y_side_by_side = pd.DataFrame({\"y_test\": y_test, \"y_pred\": y_pred_test})\n",
    "# y_diff = y_side_by_side[y_side_by_side[\"y_test\"] != y_side_by_side[\"y_pred\"]]\n",
    "# label_cats = [[\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"],\n",
    "#               [\"Insufficient_Weight\", \"Normal_Weight\", \"Overweight_Level_I\", \"Overweight_Level_II\", \"Obesity_Type_I\", \"Obesity_Type_II\", \"Obesity_Type_III\"]]\n",
    "# enc = preprocessing.OrdinalEncoder(categories=label_cats)\n",
    "# y_diff = enc.fit_transform(y_diff)\n",
    "# y_diff = pd.DataFrame(y_diff, columns=[\"y_test\", \"y_pred\"])\n",
    "\n",
    "# y_diff[\"class_diff\"] = np.abs(y_diff[\"y_test\"] - y_diff[\"y_pred\"])\n",
    "# np.count_nonzero(y_diff[\"class_diff\"] > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final predictions\n",
    "df_test = pd.read_csv(os.path.join(ROOT, 'test.csv'))\n",
    "X_test_final = feature_eng(df_test)\n",
    "\n",
    "y_pred = model.predict(X_test_final)\n",
    "df_test[\"NObeyesdad\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for submission\n",
    "df_test[[\"id\", \"NObeyesdad\"]].to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
