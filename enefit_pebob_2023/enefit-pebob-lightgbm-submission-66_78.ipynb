{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"üôè This notebook builds off of the work of @greysky's [Enefit Generic Notebook](https://www.kaggle.com/code/greysky/enefit-generic-notebook) and @patrick0302's [Do you desire sun power](https://www.kaggle.com/code/patrick0302/do-you-desire-sun-power)\n\nWe will build two models, one for energy production and one for energy consumption, and build our prediction from the output of these two.","metadata":{}},{"cell_type":"code","source":"import holidays\nimport os\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.ensemble import VotingRegressor\n\nimport lightgbm as lgb\n\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:07.471465Z","iopub.execute_input":"2023-12-26T19:33:07.471943Z","iopub.status.idle":"2023-12-26T19:33:13.976680Z","shell.execute_reply.started":"2023-12-26T19:33:07.471901Z","shell.execute_reply":"2023-12-26T19:33:13.975203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MonthlyKFold:\n    def __init__(self, n_splits=3):\n        self.n_splits = n_splits\n        \n    def split(self, X, y, groups=None):\n        dates = 12 * X[\"year\"] + X[\"month\"]\n        timesteps = sorted(dates.unique().tolist())\n        X = X.reset_index()\n        \n        for t in timesteps[-self.n_splits:]:\n            idx_train = X[dates.values < t].index\n            idx_test = X[dates.values == t].index\n            \n            yield idx_train, idx_test\n            \n    def get_n_splits(self, X, y, groups=None):\n        return self.n_splits","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:13.979609Z","iopub.execute_input":"2023-12-26T19:33:13.980194Z","iopub.status.idle":"2023-12-26T19:33:13.992202Z","shell.execute_reply.started":"2023-12-26T19:33:13.980145Z","shell.execute_reply":"2023-12-26T19:33:13.990841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_eng(df_data, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target):\n    df_data = (\n        df_data\n        .with_columns(\n            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n        )\n    )\n    \n    df_client = (\n        df_client\n        .with_columns(\n            (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n        )\n    )\n    \n    df_gas = (\n        df_gas\n        .rename({\"forecast_date\": \"date\"})\n        .with_columns(\n            (pl.col(\"date\") + pl.duration(days=1)).cast(pl.Date)\n        )\n    )\n    \n    df_electricity = (\n        df_electricity\n        .rename({\"forecast_date\": \"datetime\"})\n        .with_columns(\n            pl.col(\"datetime\") + pl.duration(days=1)\n        )\n    )\n    \n    df_location = (\n        df_location\n        .with_columns(\n            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n            pl.col(\"longitude\").cast(pl.datatypes.Float32)\n        )\n    )\n    \n    df_forecast = (\n        df_forecast\n        .rename({\"forecast_datetime\": \"datetime\"})\n        .filter((pl.col(\"hours_ahead\") >= 24) & pl.col(\"hours_ahead\") <= 48)\n        .drop(\"hours_ahead\")\n        .with_columns(\n            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n            pl.col(\"longitude\").cast(pl.datatypes.Float32),\n#             pl.col('datetime').dt.convert_time_zone(\"Europe/Bucharest\").dt.replace_time_zone(None).cast(pl.Datetime(\"us\")),\n#             pl.col('datetime').dt.replace_time_zone(None).cast(pl.Datetime(\"us\"))\n        )\n        .join(df_location, how=\"left\", on=[\"longitude\", \"latitude\"])\n        .drop(\"longitude\", \"latitude\")\n    )\n    \n    df_historical = (\n        df_historical\n        .with_columns(\n            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n            pl.col(\"longitude\").cast(pl.datatypes.Float32),\n#             pl.col(\"datetime\") + pl.duration(hours=37)\n        )\n        .join(df_location, how=\"left\", on=[\"longitude\", \"latitude\"])\n        .drop(\"longitude\", \"latitude\")\n    )\n    \n    df_forecast_date = (\n        df_forecast\n        .group_by(\"datetime\").mean()\n        .drop(\"county\")\n    )\n    \n    df_forecast_local = (\n        df_forecast\n        .filter(pl.col(\"county\").is_not_null())\n        .group_by(\"county\", \"datetime\").mean()\n    )\n    \n    df_historical_date = (\n        df_historical\n        .group_by(\"datetime\").mean()\n        .drop(\"county\")\n    )\n    \n    df_historical_local = (\n        df_historical\n        .filter(pl.col(\"county\").is_not_null())\n        .group_by(\"county\", \"datetime\").mean()\n    )\n    \n    df_data = (\n        df_data\n        .join(df_gas, on=\"date\", how=\"left\")\n        .join(df_client, on=[\"county\", \"is_business\", \"product_type\", \"date\"], how=\"left\")\n        .join(df_electricity, on=\"datetime\", how=\"left\")\n        \n        .join(df_forecast_date, on=\"datetime\", how=\"left\", suffix=\"_fd\")\n        .join(df_forecast_local, on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl\")\n        .join(df_historical_date, on=\"datetime\", how=\"left\", suffix=\"_hd\")\n        .join(df_historical_local, on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl\")\n        \n        .join(df_forecast_date.with_columns(pl.col(\"datetime\") + pl.duration(days=3)), on=\"datetime\", how=\"left\", suffix=\"_fd_3\")\n        .join(df_forecast_local.with_columns(pl.col(\"datetime\") + pl.duration(days=3)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl_3\")\n        .join(df_historical_date.with_columns(pl.col(\"datetime\") + pl.duration(days=3)), on=\"datetime\", how=\"left\", suffix=\"_hd_3\")\n        .join(df_historical_local.with_columns(pl.col(\"datetime\") + pl.duration(days=3)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_3\")\n\n        .join(df_forecast_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_fd_7\")\n        .join(df_forecast_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl_7\")\n        .join(df_historical_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_hd_7\")\n        .join(df_historical_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_7\")\n        \n        .join(df_forecast_date.with_columns(pl.col(\"datetime\") + pl.duration(days=14)), on=\"datetime\", how=\"left\", suffix=\"_fd_14\")\n        .join(df_forecast_local.with_columns(pl.col(\"datetime\") + pl.duration(days=14)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl_14\")\n        .join(df_historical_date.with_columns(pl.col(\"datetime\") + pl.duration(days=14)), on=\"datetime\", how=\"left\", suffix=\"_hd_14\")\n        .join(df_historical_local.with_columns(pl.col(\"datetime\") + pl.duration(days=14)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl_14\")\n        \n#         .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=1)).rename({\"target\": \"target_1\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=2)).rename({\"target\": \"target_2\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=3)).rename({\"target\": \"target_3\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=4)).rename({\"target\": \"target_4\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=5)).rename({\"target\": \"target_5\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=6)).rename({\"target\": \"target_6\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=7)).rename({\"target\": \"target_7\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=14)).rename({\"target\": \"target_14\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n#         .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=21)).rename({\"target\": \"target_21\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n#         .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=28)).rename({\"target\": \"target_28\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        \n        .with_columns(\n            pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n            pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n            pl.col(\"datetime\").dt.day().alias(\"day\"),\n            pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n            pl.col(\"datetime\").dt.month().alias(\"month\"),\n            pl.col(\"datetime\").dt.year().alias(\"year\"),\n        )\n        \n        .with_columns(\n            pl.concat_str(\"county\", \"is_business\", \"product_type\", \"is_consumption\", separator=\"_\").alias(\"category_1\"),\n        )\n        \n        .with_columns(\n            (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n            (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n            (np.pi * pl.col(\"day\") / 15).sin().alias(\"sin(dayofmonth)\"),\n            (np.pi * pl.col(\"day\") / 15).cos().alias(\"cos(dayofmonth)\"),\n            (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n            (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n        )\n        \n        .with_columns(\n            pl.col(pl.Float64).cast(pl.Float32),\n        )\n        \n        .drop(\"date\", \"datetime\", \"hour\", \"dayofyear\")\n    )\n    \n    return df_data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:13.994414Z","iopub.execute_input":"2023-12-26T19:33:13.995351Z","iopub.status.idle":"2023-12-26T19:33:14.044741Z","shell.execute_reply.started":"2023-12-26T19:33:13.995310Z","shell.execute_reply":"2023-12-26T19:33:14.043223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_pandas(X, y=None):\n    cat_cols = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"category_1\", \"is_holiday\"]\n    \n    if y is not None:\n        df = pd.concat([X.to_pandas(), y.to_pandas()], axis=1)\n    else:\n        df = X.to_pandas()    \n\n    # Identify holidays as a binary feature\n    estonian_holidays = holidays.country_holidays('EE', years=range(2021, 2026))\n    estonian_holidays_keys = list(estonian_holidays.keys())\n    df[\"temp_date\"] = pd.to_datetime(df[['year', 'month', 'day']])\n    df['is_holiday'] = df[\"temp_date\"].isin(estonian_holidays_keys).astype(int)\n    df.drop(\"temp_date\", axis=1, inplace=True)\n        \n    df = df.set_index(\"row_id\")\n    df[cat_cols] = df[cat_cols].astype(\"category\")\n    \n    df[\"target_mean\"] = df[[f\"target_{i}\" for i in range(2, 7)]].mean(1)\n    df[\"target_std\"] = df[[f\"target_{i}\" for i in range(2, 7)]].std(1)\n    df[\"target_ratio_7\"] = df[\"target_7\"] / (df[\"target_14\"] + 1e-3)\n#     df[\"target_ratio_14\"] = df[\"target_14\"] / (df[\"target_28\"] + 1e-3)\n    \n#     df.drop([f\"target_{i}\" for i in range(2, 7)], axis=1, inplace=True)\n\n#     # Add the log of some important features to account for outlier data\n#     log_features = [\"target_2\", \"target_3\", \"target_4\", \"target_5\", \"target_6\", \"target_7\", \"target_14\", \"target_mean\",\n#                     \"eic_count\", \"installed_capacity\", \"direct_solar_radiation_fl\", \"direct_solar_radiation\", \n#                     \"surface_solar_radiation_downwards_fl\",\"surface_solar_radiation_downwards\"]\n#     for col in log_features:\n#         df[\"log_\" + col] = np.log(df[col] + 1e-3)\n\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:14.049557Z","iopub.execute_input":"2023-12-26T19:33:14.050160Z","iopub.status.idle":"2023-12-26T19:33:14.062839Z","shell.execute_reply.started":"2023-12-26T19:33:14.050120Z","shell.execute_reply":"2023-12-26T19:33:14.061384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lgb_objective(trial):\n    params = {\n        'n_iter'           : 1000,\n        'verbose'          : -1,\n        'random_state'     : 42,\n        'objective'        : 'l1',\n        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.1),\n        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'colsample_bynode' : trial.suggest_float('colsample_bynode', 0.5, 1.0),\n        'lambda_l1'        : trial.suggest_float('lambda_l1', 1e-2, 10.0),\n        'lambda_l2'        : trial.suggest_float('lambda_l2', 1e-2, 10.0),\n        'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 4, 512),\n        'max_depth'        : trial.suggest_int('max_depth', 5, 12),\n        'max_bin'          : trial.suggest_int('max_bin', 32, 1024),\n        'num_leaves'       : trial.suggest_int('num_leaves', 16, 512),\n    }\n    \n    model  = lgb.LGBMRegressor(**params)\n    X, y   = df_train[df_train['is_consumption']==0].drop(columns=[\"target\"]), df_train[df_train['is_consumption']==0][\"target\"]\n    cv     = MonthlyKFold(1)\n    scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error')\n    \n    return -1 * np.mean(scores)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:14.064728Z","iopub.execute_input":"2023-12-26T19:33:14.065671Z","iopub.status.idle":"2023-12-26T19:33:14.079394Z","shell.execute_reply.started":"2023-12-26T19:33:14.065622Z","shell.execute_reply":"2023-12-26T19:33:14.077871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To kick things off, we begin by performing a pivoting operation on the training data to obtain distinct time series.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/predict-energy-behavior-of-prosumers/train.csv\")\n\n# Pivot the training data to have a cleaner DataFrame where we can analyze the mean target values\n# organized by datetime and various categorical variables.\npivot_train = train.pivot_table(index='datetime',columns=['county','product_type','is_business','is_consumption'], values='target', aggfunc='mean')\n\n# Renaming columns for easier access and interpretation\npivot_train.columns = ['county{}_productType{}_isBusiness{}_isConsumption{}'.format(*col) for col in pivot_train.columns.values]\npivot_train.index = pd.to_datetime(pivot_train.index)\n\npivot_train","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:33:14.081259Z","iopub.execute_input":"2023-12-26T19:33:14.081935Z","iopub.status.idle":"2023-12-26T19:33:19.826271Z","shell.execute_reply.started":"2023-12-26T19:33:14.081899Z","shell.execute_reply":"2023-12-26T19:33:19.824923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upon visualizing the data for the past year, with daily average values plotted, an intriguing pattern emerges among the 138 time series. They can be classified into two distinct groups based on their trends ‚Äî either an upward trajectory or a downward one.\n\nAs you may have already knew, the upward-trending series predominantly represent energy consumption, while the downward-trending ones are mostly energy production, specifically solar power generation.","metadata":{}},{"cell_type":"code","source":"df_plot = pivot_train.copy()\ndf_plot = (df_plot - df_plot.min())/(df_plot.max() - df_plot.min())\ndf_plot_resampled_D = df_plot.resample('D').mean()\n\n# Plot the consumption data with alpha=0.1 \ndf_plot_resampled_D.loc['2022-7':].plot(alpha=0.1, color='gray', figsize=(15, 6), legend=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:19.828121Z","iopub.execute_input":"2023-12-26T19:33:19.828603Z","iopub.status.idle":"2023-12-26T19:33:22.215942Z","shell.execute_reply.started":"2023-12-26T19:33:19.828561Z","shell.execute_reply":"2023-12-26T19:33:22.214418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If we color these time series using the values from the `is_consumption` variable, with 0 denoting green and 1 representing blue, it becomes evident that the **green lines consistently align with solar radiation**, as illustrated in the subsequent plot.","metadata":{}},{"cell_type":"code","source":"# Select the relevant columns and time range\ncolumns_consumption_0 = df_plot_resampled_D.columns[df_plot_resampled_D.columns.str.contains('isConsumption0')]\ncolumns_consumption_1 = df_plot_resampled_D.columns[df_plot_resampled_D.columns.str.contains('isConsumption1')]\n\n# Create a single legend for each category\nplt.figure(figsize=(15, 6))\nplt.plot([], color='blue', label='is_Consumption = 1')\nplt.plot([], color='green', label='is_Consumption = 0')\nplt.legend()\n\n# Plot the data for is_Consumption = 0 in green\nfor column in columns_consumption_0:\n    df_plot_resampled_D.loc['2022-7':, column].plot(alpha=0.1, color='green', legend=False)\n\n# Plot the data for is_Consumption = 1 in blue\nfor column in columns_consumption_1:\n    df_plot_resampled_D.loc['2022-7':, column].plot(alpha=0.1, color='blue', legend=False)\n\n# Add a single legend to the plot\n#plt.legend()\n\n# Show the plot\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-26T19:33:22.217850Z","iopub.execute_input":"2023-12-26T19:33:22.218694Z","iopub.status.idle":"2023-12-26T19:33:27.370515Z","shell.execute_reply.started":"2023-12-26T19:33:22.218644Z","shell.execute_reply":"2023-12-26T19:33:27.369132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This forms the foundation of our hypothesis that developing a separate model for energy production data could be beneficial, given the distinct characteristics of energy production when compared to consumption.","metadata":{}},{"cell_type":"markdown","source":"The subsequent code modifications involve the introduction of a new lightGBM model for production data (where df_train[\"is_consumption\"] == 0), and the replacement of the production predictions with the new solar model's output in the final submission, while all other prediction values remain the same with the original model.","metadata":{}},{"cell_type":"markdown","source":"# Do you feel the sun power? üòé","metadata":{}},{"cell_type":"code","source":"root = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n\ndata_cols        = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\nclient_cols      = ['product_type', 'county', 'eic_count', 'installed_capacity', 'is_business', 'date']\ngas_cols         = ['forecast_date', 'lowest_price_per_mwh', 'highest_price_per_mwh']\nelectricity_cols = ['forecast_date', 'euros_per_mwh']\nforecast_cols    = ['latitude', 'longitude', 'hours_ahead', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'forecast_datetime', 'direct_solar_radiation', 'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation']\nhistorical_cols  = ['datetime', 'temperature', 'dewpoint', 'rain', 'snowfall', 'surface_pressure','cloudcover_total','cloudcover_low','cloudcover_mid','cloudcover_high','windspeed_10m','winddirection_10m','shortwave_radiation','direct_solar_radiation','diffuse_radiation','latitude','longitude']\nlocation_cols    = ['longitude', 'latitude', 'county']\ntarget_cols      = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']\n\nsave_path = None\nload_path = None","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-26T19:33:27.372184Z","iopub.execute_input":"2023-12-26T19:33:27.372579Z","iopub.status.idle":"2023-12-26T19:33:27.383696Z","shell.execute_reply.started":"2023-12-26T19:33:27.372547Z","shell.execute_reply":"2023-12-26T19:33:27.382026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data        = pl.read_csv(os.path.join(root, \"train.csv\"), columns=data_cols, try_parse_dates=True)\ndf_client      = pl.read_csv(os.path.join(root, \"client.csv\"), columns=client_cols, try_parse_dates=True)\ndf_gas         = pl.read_csv(os.path.join(root, \"gas_prices.csv\"), columns=gas_cols, try_parse_dates=True)\ndf_electricity = pl.read_csv(os.path.join(root, \"electricity_prices.csv\"), columns=electricity_cols, try_parse_dates=True)\ndf_forecast    = pl.read_csv(os.path.join(root, \"forecast_weather.csv\"), columns=forecast_cols, try_parse_dates=True)\ndf_historical  = pl.read_csv(os.path.join(root, \"historical_weather.csv\"), columns=historical_cols, try_parse_dates=True)\ndf_location    = pl.read_csv(os.path.join(root, \"weather_station_to_county_mapping.csv\"), columns=location_cols, try_parse_dates=True)\ndf_target      = df_data.select(target_cols)\n\nschema_data        = df_data.schema\nschema_client      = df_client.schema\nschema_gas         = df_gas.schema\nschema_electricity = df_electricity.schema\nschema_forecast    = df_forecast.schema\nschema_historical  = df_historical.schema\nschema_target      = df_target.schema","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-26T19:33:27.389124Z","iopub.execute_input":"2023-12-26T19:33:27.389645Z","iopub.status.idle":"2023-12-26T19:33:33.206962Z","shell.execute_reply.started":"2023-12-26T19:33:27.389607Z","shell.execute_reply":"2023-12-26T19:33:33.205549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"X, y = df_data.drop(\"target\"), df_data.select(\"target\")\n\nX = feature_eng(X, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n\ndf_train = to_pandas(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:33:33.208853Z","iopub.execute_input":"2023-12-26T19:33:33.209606Z","iopub.status.idle":"2023-12-26T19:33:50.696120Z","shell.execute_reply.started":"2023-12-26T19:33:33.209561Z","shell.execute_reply":"2023-12-26T19:33:50.694684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train on only the last 12 months of data + first half of this year\n# df_train = df_train[df_train[\"target\"].notnull() & (df_train[\"year\"].ge(2022))]\ndf_train = df_train[df_train[\"target\"].notnull()]","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:33:50.697858Z","iopub.execute_input":"2023-12-26T19:33:50.698619Z","iopub.status.idle":"2023-12-26T19:33:51.511297Z","shell.execute_reply.started":"2023-12-26T19:33:50.698577Z","shell.execute_reply":"2023-12-26T19:33:51.509704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### HyperParam Optimization","metadata":{}},{"cell_type":"markdown","source":"Note, each iteration of hyperparameter optimization takes about 3min 30secs to run","metadata":{}},{"cell_type":"code","source":"# study = optuna.create_study(direction='minimize', study_name='Regressor')\n# study.optimize(lgb_objective, n_trials=10, show_progress_bar=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:33:51.513248Z","iopub.execute_input":"2023-12-26T19:33:51.513804Z","iopub.status.idle":"2023-12-26T19:33:51.519986Z","shell.execute_reply.started":"2023-12-26T19:33:51.513743Z","shell.execute_reply":"2023-12-26T19:33:51.518602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New strategy - pick 5 good sets of params based on Optuna and train 5 different GBM regressors with them\nc_params_1 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.04821377423576645, 'colsample_bytree': 0.5497196655514527, 'colsample_bynode': 0.5274840071632579, 'lambda_l1': 9.77879680143732, 'lambda_l2': 5.791892001041021, 'min_data_in_leaf': 481, 'max_depth': 11, 'max_bin': 511, 'num_leaves': 129\n}\n\nc_params_2 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.0648413470041428, 'colsample_bytree': 0.9238860133873772, 'colsample_bynode': 0.9327729120937044, 'lambda_l1': 1.0514727461524573, 'lambda_l2': 5.8473607663399685, 'min_data_in_leaf': 397, 'max_depth': 9, 'max_bin': 246, 'num_leaves': 381\n} \n\nc_params_3 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.05315768053078176, 'colsample_bytree': 0.6787574884682299, 'colsample_bynode': 0.5943348870186838, 'lambda_l1': 3.1690894965046614, 'lambda_l2': 7.5744315883391735, 'min_data_in_leaf': 143, 'max_depth': 12, 'max_bin': 670, 'num_leaves': 489\n}\n\nc_params_4 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.023198448443733553, 'colsample_bytree': 0.9963976012610497, 'colsample_bynode': 0.632271439449325, 'lambda_l1': 5.262597596637711, 'lambda_l2': 1.990267982972063, 'min_data_in_leaf': 431, 'max_depth': 10, 'max_bin': 612, 'num_leaves': 367\n}\n\nc_params_5 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.0921786254132783, 'colsample_bytree': 0.707024903411793, 'colsample_bynode': 0.6296431177800739, 'lambda_l1': 0.19057707138540486, 'lambda_l2': 0.3693298584783809, 'min_data_in_leaf': 469, 'max_depth': 8, 'max_bin': 318, 'num_leaves': 290\n}\n\n# Repeat this process for the models used for energy production\np_params_1 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.0694601099159599, 'colsample_bytree': 0.9402567874359262, 'colsample_bynode': 0.5997215103835294, 'lambda_l1': 8.324749667075178, 'lambda_l2': 3.8152229017561003, 'min_data_in_leaf': 45, 'max_depth': 12, 'max_bin': 885, 'num_leaves': 315\n}\n\np_params_2 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.0833938661632418, 'colsample_bytree': 0.6143745897951222, 'colsample_bynode': 0.6322055379594584, 'lambda_l1': 8.419801316576436, 'lambda_l2': 1.07301441651146, 'min_data_in_leaf': 454, 'max_depth': 12, 'max_bin': 970, 'num_leaves': 127\n}\n\np_params_3 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.09398750601092679, 'colsample_bytree': 0.6280596991836258, 'colsample_bynode': 0.6379779219482682, 'lambda_l1': 4.221770392358979, 'lambda_l2': 5.713993750225508, 'min_data_in_leaf': 180, 'max_depth': 11, 'max_bin': 544, 'num_leaves': 266\n}\n\np_params_4 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.05433580227049732, 'colsample_bytree': 0.8386685084562422, 'colsample_bynode': 0.9310187766170934, 'lambda_l1': 7.3906618978965195, 'lambda_l2': 6.073387950064185, 'min_data_in_leaf': 177, 'max_depth': 12, 'max_bin': 577, 'num_leaves': 487\n}\n\np_params_5 = {\n    'n_iter': 1000, 'verbose': -1, 'objective': 'l1', 'learning_rate': 0.09088669147433569, 'colsample_bytree': 0.7020454250886452, 'colsample_bynode': 0.9844810334453777, 'lambda_l1': 6.553300533986207, 'lambda_l2': 0.3035575347785749, 'min_data_in_leaf': 151, 'max_depth': 9, 'max_bin': 980, 'num_leaves': 429\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:33:51.521708Z","iopub.execute_input":"2023-12-26T19:33:51.522194Z","iopub.status.idle":"2023-12-26T19:33:51.535242Z","shell.execute_reply.started":"2023-12-26T19:33:51.522160Z","shell.execute_reply":"2023-12-26T19:33:51.533458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation","metadata":{}},{"cell_type":"code","source":"'''result = cross_validate(\n    estimator=lgb.LGBMRegressor(**c_params_1, random_state=42),\n    X=df_train[df_train['is_consumption']==1].drop(columns=[\"target\"]), \n    y=df_train[df_train['is_consumption']==1][\"target\"],\n    scoring=\"neg_mean_absolute_error\",\n    cv=MonthlyKFold(1),\n)\n\nresult_solar = cross_validate(\n    estimator=lgb.LGBMRegressor(**p_params_1, random_state=42),\n    X=df_train[df_train['is_consumption']==0].drop(columns=[\"target\"]), \n    y=df_train[df_train['is_consumption']==0][\"target\"],\n    scoring=\"neg_mean_absolute_error\",\n    cv=MonthlyKFold(1),\n)\n\nprint(f\"Fit Time(s): {result['fit_time'].mean():.3f}\")\nprint(f\"Score Time(s): {result['score_time'].mean():.3f}\")\nprint(f\"Error(MAE): {-result['test_score'].mean():.3f}\")\n\nprint(f\"Fit Time(s): {result_solar['fit_time'].mean():.3f}\")\nprint(f\"Score Time(s): {result_solar['score_time'].mean():.3f}\")\nprint(f\"Error(MAE): {-result_solar['test_score'].mean():.3f}\")'''","metadata":{"execution":{"iopub.status.busy":"2023-12-26T20:12:04.455770Z","iopub.execute_input":"2023-12-26T20:12:04.456206Z","iopub.status.idle":"2023-12-26T20:19:50.211865Z","shell.execute_reply.started":"2023-12-26T20:12:04.456171Z","shell.execute_reply":"2023-12-26T20:19:50.210250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"if load_path is not None:\n    load_solar_path = \"_solar.\".join(load_path.split(\".\"))\n    model = pickle.load(open(load_path, \"rb\"))\n    model_solar = pickle.load(open(load_solar_path, \"rb\"))\nelse:\n    model = VotingRegressor([\n        ('lgb_1', lgb.LGBMRegressor(**c_params_1, random_state=100)), \n        ('lgb_2', lgb.LGBMRegressor(**c_params_2, random_state=101)), \n        ('lgb_3', lgb.LGBMRegressor(**c_params_3, random_state=102)), \n        ('lgb_4', lgb.LGBMRegressor(**c_params_4, random_state=103)), \n        ('lgb_5', lgb.LGBMRegressor(**c_params_5, random_state=104)), \n    ])\n    \n    model_solar = VotingRegressor([\n        ('lgb_6', lgb.LGBMRegressor(**p_params_1, random_state=105)), \n        ('lgb_7', lgb.LGBMRegressor(**p_params_2, random_state=106)), \n        ('lgb_8', lgb.LGBMRegressor(**p_params_3, random_state=107)), \n        ('lgb_9', lgb.LGBMRegressor(**p_params_4, random_state=108)), \n        ('lgb_10', lgb.LGBMRegressor(**p_params_5, random_state=109)), \n    ])\n    \n    model.fit(\n        X=df_train[df_train['is_consumption']==1].drop(columns=[\"target\"]),\n        y=df_train[df_train['is_consumption']==1][\"target\"]\n    )\n    \n    model_solar.fit(\n        X=df_train[df_train['is_consumption']==0].drop(columns=[\"target\"]),\n        y=df_train[df_train['is_consumption']==0][\"target\"]\n    )\n\nif save_path is not None:\n    save_solar_path = \"_solar.\".join(save_path.split(\".\"))\n    with open(save_path, \"wb\") as f:\n        pickle.dump(model, f)\n    with open(save_solar_path, \"wb\") as f:\n        pickle.dump(model_solar, f)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:33:51.561661Z","iopub.execute_input":"2023-12-26T19:33:51.562153Z","iopub.status.idle":"2023-12-26T20:12:03.202770Z","shell.execute_reply.started":"2023-12-26T19:33:51.562110Z","shell.execute_reply":"2023-12-26T20:12:03.201323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Analysis","metadata":{}},{"cell_type":"code","source":"lgb.plot_importance(model.estimators_[0], max_num_features=20, figsize=(8, 8))","metadata":{"execution":{"iopub.status.busy":"2023-12-26T20:12:03.204605Z","iopub.execute_input":"2023-12-26T20:12:03.205097Z","iopub.status.idle":"2023-12-26T20:12:03.807901Z","shell.execute_reply.started":"2023-12-26T20:12:03.205037Z","shell.execute_reply":"2023-12-26T20:12:03.806579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb.plot_importance(model_solar.estimators_[0], max_num_features=20, figsize=(8, 8))","metadata":{"execution":{"iopub.status.busy":"2023-12-26T20:12:03.809551Z","iopub.execute_input":"2023-12-26T20:12:03.810118Z","iopub.status.idle":"2023-12-26T20:12:04.451670Z","shell.execute_reply.started":"2023-12-26T20:12:03.810039Z","shell.execute_reply":"2023-12-26T20:12:04.450345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"import enefit\n\nenv = enefit.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2023-12-12T17:56:13.434851Z","iopub.execute_input":"2023-12-12T17:56:13.435430Z","iopub.status.idle":"2023-12-12T17:56:13.478863Z","shell.execute_reply.started":"2023-12-12T17:56:13.435401Z","shell.execute_reply":"2023-12-12T17:56:13.477939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test, revealed_targets, client, historical_weather,\n        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n    \n    test = test.rename(columns={\"prediction_datetime\": \"datetime\"})\n    \n    df_test           = pl.from_pandas(test[data_cols[1:]], schema_overrides=schema_data)\n    df_client         = pl.from_pandas(client[client_cols], schema_overrides=schema_client)\n    df_gas            = pl.from_pandas(gas_prices[gas_cols], schema_overrides=schema_gas)\n    df_electricity    = pl.from_pandas(electricity_prices[electricity_cols], schema_overrides=schema_electricity)\n    df_new_forecast   = pl.from_pandas(forecast_weather[forecast_cols], schema_overrides=schema_forecast)\n    df_new_historical = pl.from_pandas(historical_weather[historical_cols], schema_overrides=schema_historical)\n    df_new_target     = pl.from_pandas(revealed_targets[target_cols], schema_overrides=schema_target)\n    \n    df_forecast       = pl.concat([df_forecast, df_new_forecast]).unique()\n    df_historical     = pl.concat([df_historical, df_new_historical]).unique()\n    df_target         = pl.concat([df_target, df_new_target]).unique()\n    \n    X_test = feature_eng(df_test, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n    X_test = to_pandas(X_test)\n    \n    test['target'] = model.predict(X_test).clip(0)\n    test['target_solar'] = model_solar.predict(X_test).clip(0)\n    test.loc[test['is_consumption']==0, \"target\"] = test.loc[test['is_consumption']==0, \"target_solar\"]    \n    \n    sample_prediction[\"target\"] = test['target']\n    \n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T17:56:13.480092Z","iopub.execute_input":"2023-12-12T17:56:13.480626Z","iopub.status.idle":"2023-12-12T17:56:40.537600Z","shell.execute_reply.started":"2023-12-12T17:56:13.480596Z","shell.execute_reply":"2023-12-12T17:56:40.536401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}